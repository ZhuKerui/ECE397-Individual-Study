{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded checkpoint 'data/result_1/best_model.pt' (epoch 18 iter: 690001 train_loss: 1.6085507930369372, dev_loss: 2.29362431439209, train_pos:0.5143910646438599, train_neg: 0.01834769733250141, dev_pos: 0.28918400406837463, dev_neg: 0.015907999128103256)\n"
     ]
    }
   ],
   "source": [
    "from embeddings.demo import Demo\n",
    "import spacy\n",
    "\n",
    "d = Demo('data/result_1/best_model.pt', 'data/result_1/saved_config.json', 'data/rel_20.txt')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import rouge_n_sentence_level\n",
    "def sent_normalize(sent:str):\n",
    "    tokens = nlp(sent)\n",
    "    normalized = []\n",
    "    for token in tokens:\n",
    "        if token.pos_ == 'ADV':\n",
    "            continue\n",
    "        else:\n",
    "            normalized.append(token.lemma_)\n",
    "    return ' '.join(normalized)\n",
    "\n",
    "def my_rouge(a:str,b:str):\n",
    "    a_ = a.split()\n",
    "    b_ = b.split()\n",
    "    summary, reference = (a_, b_) if len(a_)>=len(b_) else (b_, a_)\n",
    "    score = rouge_n_sentence_level(summary, reference, n=1)\n",
    "    return score.recall, ' '.join(reference)\n",
    "\n",
    "def move_redundency(sents:list):\n",
    "    ret = []\n",
    "    for sent in sents:\n",
    "        if not ret:\n",
    "            ret.append(sent)\n",
    "            continue\n",
    "        is_redundent = False\n",
    "        i = 0\n",
    "        while i < len(ret):\n",
    "            ret_sent = ret[i]\n",
    "            score, shorter_sent = my_rouge(ret_sent, sent)\n",
    "            if score >= 0.7:\n",
    "                if ret_sent == shorter_sent:\n",
    "                    is_redundent = True\n",
    "                    break\n",
    "                else:\n",
    "                    ret.remove(ret_sent)\n",
    "            else:\n",
    "                i += 1\n",
    "        if not is_redundent:\n",
    "            ret.append(sent)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the top matched relations\n",
    "subject = 'linear regression'.split()\n",
    "object = 'data mining'.split()\n",
    "display_num = 60\n",
    "\n",
    "result = d.find_closest_relation(subject, object, display_num)\n",
    "result = [line.split('<pad>', 1)[0] for line in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('are popular tools for ', 2.8260436)\n('are suboptimal for ', 2.7709877)\n('are powerful methods for ', 2.6435244)\n('been applied for ', 2.6390243)\n('are technique for ', 2.5502396)\n('been applied in ', 2.3141925)\n('are approach for ', 2.3084748)\n('are used for ', 2.2900667)\n('is widely employed for ', 2.2461405)\n('is often used in ', 2.2136934)\n('are method for ', 2.190134)\n('are more suitable for ', 2.1745002)\n('has been widely used for ', 2.1741714)\n('was used in ', 2.1066484)\n('be widely used in ', 2.082003)\n('are widely adopted in ', 2.0813704)\n('is widely used to ', 2.0643475)\n('are successfully used in ', 2.0634754)\n('be effectively used for ', 2.0526202)\n('is commonly used for ', 2.052291)\n('are tasks for ', 2.049424)\n"
     ]
    }
   ],
   "source": [
    "# Remove redundent relations and showing the similarity\n",
    "clean_result_raw = move_redundency(result)\n",
    "score = d.cal_score(subject, object, clean_result_raw)\n",
    "for item in zip(clean_result_raw, score):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "be use for\nbe popular tool for\nbe suboptimal for\nbe method for\nbe suitable for\nbe apply for\nbe technique for\nuse in\nbe apply in\nbe approach for\nbe employ for\nbe adopt in\nbe use to\nbe task for\n"
     ]
    }
   ],
   "source": [
    "# Remove redundent relations after lemmatization\n",
    "normalized_result = [sent_normalize(sent) for sent in result]\n",
    "clean_result = move_redundency(normalized_result)\n",
    "print('\\n'.join(clean_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(50.9102)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "rel_1 = 'are analogues of'.split()\n",
    "rel_2 = 'is investigated under'.split()\n",
    "rel_1 += ['<pad>'] * (6 - len(rel_1))\n",
    "rel_2 += ['<pad>'] * (6 - len(rel_2))\n",
    "temp_rel = d.model.get_relation([rel_1, rel_2])\n",
    "a = temp_rel[0]\n",
    "b = temp_rel[1]\n",
    "b.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}