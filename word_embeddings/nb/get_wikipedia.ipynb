{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd0947ccf1d8baae4b0b3c7136017192ad9c9ad48a2268b8759d45f6c7f995c7f83",
   "display_name": "Python 3.6.9 64-bit ('imojie_env': virtualenvwrapper)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from tools.BasicUtils import my_read, my_write, MultiThreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect wiki summary and process the text\n",
    "def get_wiki_summary_from_kw(line:str):\n",
    "    try:\n",
    "        page = wikipedia.page(line)\n",
    "        # if line.lower() == page.title.lower():\n",
    "        #     return ' '.join(page.summary.split())\n",
    "        return ' '.join(page.summary.split())\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_wiki_context_from_kw(line:str):\n",
    "    try:\n",
    "        page = wikipedia.page(line)\n",
    "        # if line.lower() == page.title.lower():\n",
    "        #     return ' '.join(page.content.split())\n",
    "        return ' '.join(page.content.split())\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "source": [
    "Below is for temperary usage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_kws = my_read('../data/corpus/keyword_f.txt')[:1000]\n",
    "multithreading = MultiThreading()\n",
    "data = multithreading.run(get_wiki_summary_from_kw, target_kws, 10)\n",
    "my_write('wiki_summary.txt', data)\n",
    "\n",
    "!bash ../sh/remove_parens.sh wiki_summary.txt wiki_summary_f.txt\n",
    "\n",
    "!python ../py/sent_tokenize.py wiki_summary_f.txt wiki_summary_sents.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect content from wikipedia page for openie task\n",
    "\n",
    "# keywords = ['data structure', 'binary tree', 'hash table', 'linked list']\n",
    "keywords = ['programming language', 'python (programming language)', 'java language', 'javascript', 'lua language', 'scala language', 'lisp language', 'php language', 'ruby language', 'smalltalk (programming language)']\n",
    "text = []\n",
    "for kw in keywords:\n",
    "    ret = get_wiki_context_from_kw(kw)\n",
    "    if ret:\n",
    "        text.append(ret)\n",
    "my_write('wiki.txt', text)\n",
    "\n",
    "!bash ../sh/clean_corpus.sh wiki.txt wiki_f.txt\n",
    "!python ../my_sent_tokenize.py wiki_f.txt wiki_sent_temp.txt\n",
    "!bash ../sh/clean_wiki_corpus.sh wiki_sent_temp.txt pl_wiki_sents.txt\n",
    "!bash ../sh/clean_openie_corpus.sh pl_wiki_sents.txt\n",
    "\n",
    "!rm wiki.txt wiki_f.txt wiki_sent_temp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wiki_summary_from_kw('smalltalk (programming language)')"
   ]
  }
 ]
}